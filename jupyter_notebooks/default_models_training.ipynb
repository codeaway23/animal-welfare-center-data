{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of classifiers to test in default settings\n",
    "\n",
    "classifiers = {\n",
    "    'BernoulliNB': BernoulliNB(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'ExtraTreeClassifier': ExtraTreeClassifier(),\n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(3),\n",
    "    'LinearDiscriminantAnalysis': LinearDiscriminantAnalysis(),\n",
    "    'SVC': SVC(),\n",
    "    'LogisticRegression': LogisticRegression(solver='newton-cg', multi_class='multinomial'),\n",
    "    'MLPClassifier': MLPClassifier(),\n",
    "    'NearestCentroid': NearestCentroid(),\n",
    "    'QuadraticDiscriminantAnalysis': QuadraticDiscriminantAnalysis(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'RidgeClassifier': RidgeClassifier(),\n",
    "    'RidgeClassifierCV': RidgeClassifierCV(),\n",
    "    'XGBClassifier': XGBClassifier()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anujsable/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/anujsable/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# preparing train and test data\n",
    "\n",
    "train_data = pd.read_csv('../processed/train_data.csv')\n",
    "ids = train_data['animal_id_outcome']\n",
    "y = train_data['Label']\n",
    "X = train_data.drop(['Label','animal_id_outcome'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anujsable/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/anujsable/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/home/anujsable/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/anujsable/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/anujsable/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/anujsable/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# testing each classifier, storing their f1 scores (micro)\n",
    "\n",
    "f1_scores = []\n",
    "\n",
    "for clf in classifiers.values():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = f1_score(y_test, y_pred, average='micro')\n",
    "    f1_scores.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 classifiers in default settings...\n",
      "GradientBoostingClassifier F1 SCORE:  0.6236795314297667\n",
      "XGBClassifier F1 SCORE:  0.6166718962451626\n",
      "MLPClassifier F1 SCORE:  0.6030749921556322\n",
      "SVC F1 SCORE:  0.5806923961928668\n",
      "RandomForestClassifier F1 SCORE:  0.5747306767074574\n"
     ]
    }
   ],
   "source": [
    "# getting top 5 models\n",
    "\n",
    "idx = np.argsort(f1_scores)[::-1]\n",
    "best_model_keys = [list(classifiers.keys())[x] for x in idx]\n",
    "best_model_values = [classifiers[x] for x in best_model_keys]\n",
    "best_classifiers = dict(zip(best_model_keys, best_model_values))\n",
    "sorted_f1 = [f1_scores[x] for x in idx]\n",
    "\n",
    "print(\"Top 5 classifiers in default settings...\")\n",
    "for i in range(5):\n",
    "    print(list(best_classifiers.keys())[i], \"F1 SCORE: \", sorted_f1[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
